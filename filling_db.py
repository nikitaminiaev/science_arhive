import json
import os
import zipfile
import PyPDF2
import io
import logging
import warnings
from urllib.parse import unquote
from src.db_manager import PDFArchiveDatabaseManager

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è PyPDF2
warnings.filterwarnings("ignore", category=UserWarning, module="PyPDF2")
logging.getLogger("PyPDF2").setLevel(logging.ERROR)

def clean_text_encoding(text):
    """
    –û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ Unicode, –≤–∫–ª—é—á–∞—è —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã–µ –ø–∞—Ä—ã
    
    Args:
    - text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
    
    Returns:
    - –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–ª—è UTF-8
    """
    if not isinstance(text, str):
        return str(text)
    
    if not text:
        return text
    
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ/–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∑–∞–º–µ–Ω–æ–π –æ—à–∏–±–æ–∫
        cleaned = text.encode('utf-8', errors='replace').decode('utf-8')
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ–º —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        cleaned_chars = []
        for char in cleaned:
            char_code = ord(char)
            # –ò—Å–∫–ª—é—á–∞–µ–º —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã (U+D800 –¥–æ U+DFFF)
            if not (0xD800 <= char_code <= 0xDFFF):
                cleaned_chars.append(char)
            else:
                cleaned_chars.append('?')
        
        return ''.join(cleaned_chars)
        
    except Exception as e:
        # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–æ–∫—É —Å –∑–∞–º–µ–Ω—ë–Ω–Ω—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
        return str(text).encode('utf-8', errors='replace').decode('utf-8')

def extract_pdf_text_from_zip(zip_path, pdf_filename, max_pages=10, max_chars=10000):
    """
    Extract text from a PDF within a ZIP archive with metadata
    Focuses on capturing key information efficiently

    Args:
    - zip_path: Path to the ZIP archive
    - pdf_filename: Name of the PDF file within the archive
    - max_pages: Maximum number of pages to extract (default 10)
    - max_chars: Maximum number of characters to extract (default 10000)

    Returns:
    - Tuple: (extracted_text, file_size, pages_count)
    """
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # Get file size
            file_info = zip_ref.getinfo(pdf_filename)
            file_size = file_info.file_size
            
            # Read PDF data and create BytesIO stream for PyPDF2
            pdf_data = zip_ref.read(pdf_filename)
            pdf_stream = io.BytesIO(pdf_data)
            
            pdf_reader = PyPDF2.PdfReader(pdf_stream)
            pages_count = len(pdf_reader.pages)

            full_text = ""
            for page in pdf_reader.pages[:max_pages]:
                page_text = page.extract_text()
                # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                clean_page_text = clean_text_encoding(page_text)
                full_text += clean_page_text

            cleaned_text = ' '.join(full_text.split())
            truncated_text = cleaned_text[:max_chars]

            return truncated_text, file_size, pages_count

    except Exception as e:
        error_msg = f"Error extracting text from {pdf_filename}: {str(e)}"
        print(f"‚ö†Ô∏è  {error_msg}")
        # –¢–∞–∫–∂–µ –æ—á–∏—â–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
        clean_error_msg = clean_text_encoding(error_msg)
        return clean_error_msg, None, None


def write_to_file(error, zip_path, pdf_filename='', output_file='pdf_error.txt'):
    with open(output_file, 'a', encoding='utf-8', errors='replace') as f:
        # –û—á–∏—â–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –æ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
        clean_zip_path = clean_text_encoding(str(zip_path))
        clean_pdf_filename = clean_text_encoding(str(pdf_filename))
        clean_error = clean_text_encoding(str(error))
        
        f.write(f"zip_path: {clean_zip_path}\n")
        f.write(f"pdf_filename: {clean_pdf_filename}\n")
        f.write(f"error: {clean_error}\n\n")


def process_zip_archives_to_sqlite(db_manager, root_directory, batch_size=10):
    """
    Process ZIP archives and write PDF contents to SQLite database in batches

    Args:
    - db_manager: PDFArchiveDatabaseManager instance
    - root_directory: Root directory containing ZIP archives
    - batch_size: Number of records to insert in a single batch
    """
    batch = []
    metadata = json.dumps({"root_directory": root_directory})
    last_entry = db_manager.get_last_entry()
    last_processed_pdf = last_entry['pdf_filename'] if last_entry else None
    entity_count = last_entry['id'] if last_entry else None
    
    processed_count = 0
    total_archives = 0
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ ZIP –∞—Ä—Ö–∏–≤–æ–≤
    print("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏...")
    for root, dirs, files in os.walk(root_directory):
        total_archives += len([f for f in files if f.lower().endswith('.zip')])
    
    print(f"üì¶ –ù–∞–π–¥–µ–Ω–æ ZIP –∞—Ä—Ö–∏–≤–æ–≤: {total_archives}")
    current_archive = 0

    try:
        for root, dirs, files in os.walk(root_directory):
            for file in files:
                if file.lower().endswith('.zip'):
                    current_archive += 1
                    zip_path = os.path.join(root, file)
                    print(f"üìÅ [{current_archive}/{total_archives}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {file}")

                    try:
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            pdf_files = [f for f in zip_ref.namelist() if f.lower().endswith('.pdf')]
                            relative_zip_path = os.path.relpath(zip_path, root_directory)

                            # Skip this archive if entity_count > total_pdfs
                            total_pdfs = len(pdf_files)
                            if entity_count is not None and entity_count > total_pdfs:
                                entity_count -= total_pdfs
                                continue

                            for pdf_filename in pdf_files:
                                try:
                                    unicode_filename = unquote(pdf_filename)
                                    if last_processed_pdf and unicode_filename == last_processed_pdf:
                                        last_processed_pdf = None  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º, –∫–∞–∫ —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç–∏–≥–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ
                                        continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
                                    if last_processed_pdf:  # –ü–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ–∞–π–ª–∞
                                        continue

                                    raw_text, file_size, pages_count = extract_pdf_text_from_zip(zip_path, pdf_filename)
                                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
                                    clean_raw_text = clean_text_encoding(str(raw_text)) if raw_text else raw_text
                                    clean_unicode_filename = clean_text_encoding(unicode_filename)
                                    clean_relative_zip_path = clean_text_encoding(relative_zip_path)
                                    
                                    batch.append((clean_relative_zip_path, clean_unicode_filename, clean_raw_text, metadata, file_size, pages_count))
                                    
                                    processed_count += 1
                                    if processed_count % 10 == 0:
                                        print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ PDF —Ñ–∞–π–ª–æ–≤: {processed_count}")

                                    if len(batch) >= batch_size:
                                        db_manager.insert_pdf_contents_batch(batch)
                                        print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω batch –∏–∑ {len(batch)} –∑–∞–ø–∏—Å–µ–π")
                                        batch = []  # Reset batch

                                except Exception as pdf_error:
                                    print(f"Error processing PDF {pdf_filename} in {zip_path}: {pdf_error}")
                                    write_to_file(pdf_error, zip_path, pdf_filename)

                    except Exception as zip_error:
                        print(f"Error processing ZIP archive {zip_path}: {zip_error}")
                        write_to_file(zip_error, zip_path)

        # Insert any remaining records
        if batch:
            db_manager.insert_pdf_contents_batch(batch)
            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π batch –∏–∑ {len(batch)} –∑–∞–ø–∏—Å–µ–π")
        
        print(f"\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ PDF —Ñ–∞–π–ª–æ–≤: {processed_count}")
        print(f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ ZIP –∞—Ä—Ö–∏–≤–æ–≤: {current_archive}")

    except Exception as e:
        print(f"Unexpected error: {e}")


def main():
    db_name = 'archive.db'
    root_directory = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å ZIP-–∞—Ä—Ö–∏–≤–∞–º–∏: ").strip()
    db_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–Ω–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é): ").strip()
    if not db_path:
        db_path = ''

    db_manager = PDFArchiveDatabaseManager(os.path.join(db_path, db_name))

    conn = db_manager.create_database_schema()

    if conn:
        try:
            process_zip_archives_to_sqlite(db_manager, root_directory)
            print("PDF contents have been processed and stored in the database.")

        finally:
            conn.close()
    else:
        print("Failed to create database connection.")


if __name__ == "__main__":
    main()
